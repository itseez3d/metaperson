"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[421],{8142:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>c,toc:()=>d});var i=t(4848),a=t(8453);const s={sidebar_label:"Leap",description:"Leap Realistic Facial Animation"},r="Leap Realistic Facial Animation",c={id:"leap",title:"Leap Realistic Facial Animation",description:"Leap Realistic Facial Animation",source:"@site/docs/leap.md",sourceDirName:".",slug:"/leap",permalink:"/leap",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"Leap",description:"Leap Realistic Facial Animation"},sidebar:"tutorialSidebar",previous:{title:"MetaPerson Creator",permalink:"/"},next:{title:"Integration",permalink:"/business-integration/"}},o={},d=[{value:"What is Avatar SDK Leap UE plugin?",id:"what-is-avatar-sdk-leap-ue-plugin",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Minimal technical requirements",id:"minimal-technical-requirements",level:2},{value:"Sample project",id:"sample-project",level:2},{value:"Rendering Video",id:"rendering-video",level:2},{value:"Support",id:"support",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"leap-realistic-facial-animation",children:"Leap Realistic Facial Animation"}),"\n",(0,i.jsx)(n.h2,{id:"what-is-avatar-sdk-leap-ue-plugin",children:"What is Avatar SDK Leap UE plugin?"}),"\n",(0,i.jsx)(n.p,{children:"Avatar SDK Leap UE plugin simplifies the integration of revolutionary Leap Facial Capture technology with your Unreal Engine projects. After capturing your data with the Leap application for iPhone, export the collected data to your computer disk. Using this data, the Avatar SDK Leap UE plugin creates a realistic facial animation sequence for your 3D avatar in a few clicks. The plugin will create all the required assets in a few minutes, including skeletal mesh, textures, materials, and animations."}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"OS: Windows\r\nUnreal Engine version: 5.3 or 5.4\r\nYou will need an iPhone with Leap application installed to capture the facial animation data."}),"\n",(0,i.jsx)(n.h2,{id:"minimal-technical-requirements",children:"Minimal technical requirements"}),"\n",(0,i.jsx)(n.p,{children:"RAM: 16 Gb\r\nGPU: GeForce RTX 3050\r\nCPU: Intel i7 7th gen"}),"\n",(0,i.jsx)(n.h2,{id:"sample-project",children:"Sample project"}),"\n",(0,i.jsx)(n.p,{children:"The Leap plugin comes with a sample UE project to help you start with facial animation creation. Open the project by double-clicking on the LeapDemo. project file."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(9662).A+"",width:"886",height:"302"})}),"\n",(0,i.jsx)(n.p,{children:"Another option - in the Unreal Engine Project browser, click on the Browse button in the Recent Project partition and provide a path to the LeapDemo:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(6994).A+"",width:"1478",height:"1011"})}),"\n",(0,i.jsxs)(n.p,{children:["When you open the project, the Leap sample level will be loaded. You can explore the sample animation provided with the project at ",(0,i.jsx)(n.code,{children:"/Content/AvatarSdkLeap/Victor"})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(5146).A+"",width:"1470",height:"779"})}),"\n",(0,i.jsxs)(n.p,{children:["To import your animation, click the ",(0,i.jsx)(n.code,{children:"Window->Avatar SDK Leap"})," menu to open the plugin window."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(46).A+"",width:"625",height:"896"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(6622).A+"",width:"848",height:"604"})}),"\n",(0,i.jsxs)(n.p,{children:["Choose the name for your ",(0,i.jsx)(n.a,{href:"https://dev.epicgames.com/documentation/en-us/unreal-engine/sequences-shots-and-takes-in-unreal-engine#levelsequences",children:"level sequence"}),", and choose a type of avatar to be generated. Click the ",(0,i.jsx)(n.code,{children:"Use materials for Ray tracing"})," if you intend to use path tracing to render your level sequence. For your first try, we recommend leaving it in its default state."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(629).A+"",width:"848",height:"604"})}),"\n",(0,i.jsxs)(n.p,{children:["Click on the ",(0,i.jsx)(n.code,{children:"Import Leap Animation"})," button and provide a path with the archive you got after capturing data with your iPhone Leap application. After that, the processing begins."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(7156).A+"",width:"1600",height:"820"})}),"\n",(0,i.jsx)(n.p,{children:"Depending on your hardware setup, processing may take from 4 to 5 minutes.\r\nWhen the processing is finished, you will be able to open the resulting level sequence or explore the assets created by Leap in the destination folder."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(7740).A+"",width:"836",height:"596"})}),"\n",(0,i.jsxs)(n.p,{children:["The imported animation files may be found in the ",(0,i.jsx)(n.code,{children:"/Content/AvatarSdkLeap"})," directory:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(1551).A+"",width:"679",height:"328"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(8936).A+"",width:"1481",height:"463"})}),"\n",(0,i.jsx)(n.p,{children:"Created level sequence contains tracks for the camera, texture and body skeletal mesh. You can edit the created tracks and assets according to your requirements."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(3101).A+"",width:"1600",height:"451"})}),"\n",(0,i.jsxs)(n.p,{children:["A corresponding Level Sequence Actor will be placed on the current opened level. This Level Sequence Actor may be used to create cinematic content for games and traditional animation in Unreal Engine. The Actor is placed at the location that can be configured in the plugin settings ",(0,i.jsx)(n.code,{children:"Edit->Project Settings->Avatar SDK Leap"}),":"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(8180).A+"",width:"1600",height:"432"})}),"\n",(0,i.jsx)(n.h2,{id:"rendering-video",children:"Rendering Video"}),"\n",(0,i.jsx)(n.p,{children:"To render the image frame sequence from your Level Sequence, click on the corresponding button in the Sequencer:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(1894).A+"",width:"1076",height:"572"})}),"\n",(0,i.jsxs)(n.p,{children:["Choose among the predefined Rendering Settings, or create your own. We recommend to use the ",(0,i.jsx)(n.code,{children:"RA_No_PT_Config_FAST"})," to get the fastest result:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(675).A+"",width:"1020",height:"533"})}),"\n",(0,i.jsxs)(n.p,{children:["The config ",(0,i.jsx)(n.code,{children:"RA_No_PT_Config_MID"})," should give better results and does not use path tracing.\r\nThe config ",(0,i.jsx)(n.code,{children:"RA_PT_Config"})," is made for path tracing rendering. These configurations represent a trade-off between quality and rendering time.\r\nClick on the ",(0,i.jsx)(n.code,{children:"Render Local"})," button to start the rendering:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(9478).A+"",width:"1153",height:"415"})}),"\n",(0,i.jsxs)(n.p,{children:["By default, the Level Sequence will be rendered as a sequence of PNG images that can be found in the ",(0,i.jsx)(n.code,{children:"\\Saved\\MovieRenders"})," subdirectory of the project directory. Use video editing software to create video from the set of images. A good option is to use FFmpeg. In such case, the command may look like this:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'ffmpeg -r 60  -i "Saved\\MovieRenders\\LevelSequence_RealisticAnim_0.%04d.png" -c:v libx265 -crf 2 -vf format=yuv420p10le -tag:v hvc1  "I:\\renders\\video0.mp4" -y\n'})}),"\n",(0,i.jsx)(n.h2,{id:"support",children:"Support"}),"\n",(0,i.jsxs)(n.p,{children:["Please feel free to ask any questions about the Avatar SDK Leap at ",(0,i.jsx)(n.a,{href:"mailto:support@avatarsdk.com",children:"support@avatarsdk.com"})]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8936:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_assets-731573f31c735defa76b98f0b7cf3052.png"},1551:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_dest-c02b204965c2cc200f58a647f9d3d67f.png"},9662:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_dir-d95fcf0d6a9be62f8ceaca5e78180e32.png"},7156:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_import-3fab2592510f041432e558ecf2a3310e.png"},6994:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_launch-83b1cc673916b73ce693f0b9ea412d25.png"},46:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_menu-53746b213c26db54bc7a75e9867b4efd.png"},9478:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_render_start-9bb997aafd4b05a562238187ee8c9db6.png"},675:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_rendering-005019fc3d65c9c1b87cb6ae204cd565.png"},3101:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_seq1-49f86a96a90de4d7b495ba5ff693adbc.png"},1894:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_seq2-775cac7bf041eb2359dab400e833537c.png"},8180:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_settings-d6e600d916623823dcb9cc81556485e2.png"},5146:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_victor-644fb362d033cf98b5ff81b506a29f9c.png"},6622:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_window1-972e83c0c7260f90e175806791bdf226.png"},629:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_window2-f4fadfe8e6e75fbdd49a534e74f6c1f3.png"},7740:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/leap_window3-b2554426323261a45476d1c5a56b0b09.png"},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>c});var i=t(6540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);