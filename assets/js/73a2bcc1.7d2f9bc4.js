"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[421],{8142:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var i=n(4848),a=n(8453);const s={sidebar_label:"Leap",description:"Leap Realistic Facial Animation"},r="Leap Realistic Facial Animation",o={id:"leap",title:"Leap Realistic Facial Animation",description:"Leap Realistic Facial Animation",source:"@site/docs/leap.md",sourceDirName:".",slug:"/leap",permalink:"/leap",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"Leap",description:"Leap Realistic Facial Animation"},sidebar:"tutorialSidebar",previous:{title:"MetaPerson Creator",permalink:"/"},next:{title:"Integration",permalink:"/business-integration/"}},c={},l=[{value:"Leap iOS application for dataset capture",id:"leap-ios-application-for-dataset-capture",level:2},{value:"Leap UE plugin",id:"leap-ue-plugin",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Minimal technical requirements",id:"minimal-technical-requirements",level:3},{value:"Sample project",id:"sample-project",level:3},{value:"Rendering Video",id:"rendering-video",level:3},{value:"Support",id:"support",level:3}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"leap-realistic-facial-animation",children:"Leap Realistic Facial Animation"}),"\n",(0,i.jsx)(t.p,{children:"We are thrilled to announce the beta version of the Avatar SDK Leap. Leap is facial motion capture software that transforms a video of a person speaking on camera into a 3D animation of the person\u2019s avatar. By leveraging neural networks to predict the shape and texture of the avatar, Leap delivers an unprecedented level of visual quality that transcends the uncanny valley. Currently, users will need an iPhone with the Leap mobile app to record a video, but support for videos captured with standard cameras will be added shortly."}),"\n",(0,i.jsx)("div",{class:"iframe-container",children:(0,i.jsx)("iframe",{width:"560",height:"315",allow:"fullscreen",src:"https://www.youtube.com/embed/VY4kIyohjcc?si=PKIum24G0Hr9vnxx"})}),"\n",(0,i.jsx)(t.p,{children:"\xa0"}),"\n",(0,i.jsx)(t.p,{children:"Leap has two essential components that work together to bring innovative animation technology to life. The first component is a mobile app specifically designed for capturing detailed and expressive facial animation. This app allows users to easily record and process facial movements. The second component is a game engine plugin that takes this rich facial animation data and seamlessly converts it into the animation format suitable for target platform. An Unreal Engine plugin is available now, with a Unity plugin coming soon."}),"\n",(0,i.jsx)(t.h2,{id:"leap-ios-application-for-dataset-capture",children:"Leap iOS application for dataset capture"}),"\n",(0,i.jsx)(t.p,{children:"The Leap iOS app captures user facial animation data. The quality of this data greatly affects the animation, so please pay close attention to the tips we provide:"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"For the best results, position youself so your face and upper shoulders are clearly visible"}),"\n",(0,i.jsx)(t.li,{children:"Please keep your head at a slight angle - no more than 15 degrees is perfect"}),"\n",(0,i.jsx)(t.li,{children:"Try to keep still. Steady hands mean sharper shots. Let's keep things smooth!"}),"\n",(0,i.jsx)(t.li,{children:"Make sure your face is evenly lit. Balanced lighting helps capture all the details clearly!"}),"\n",(0,i.jsx)(t.li,{children:"Please keep your forehead clear of any hair. This helps capture your face more accurately."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Click on the Start button and prepare yourself for capturing animation."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(1543).A+"",width:"311",height:"673"})}),"\n",(0,i.jsx)(t.p,{children:"Click on the Record button to start capturing data."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(9468).A+"",width:"311",height:"673"})}),"\n",(0,i.jsx)(t.p,{children:"When you are ready, stop recording and export the archive with your data."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(537).A+"",width:"311",height:"673"})}),"\n",(0,i.jsx)(t.p,{children:"We'll use this archive in the next step to make facial animations."}),"\n",(0,i.jsx)(t.h2,{id:"leap-ue-plugin",children:"Leap UE plugin"}),"\n",(0,i.jsx)(t.p,{children:"Avatar SDK Leap UE plugin simplifies the integration of revolutionary Leap Facial Capture technology with your Unreal Engine projects. After capturing your data with the Leap application for iPhone, export the collected data to your computer disk. Using this data, the Avatar SDK Leap UE plugin creates a realistic facial animation sequence for your 3D avatar in a few clicks. The plugin will create all the required assets in a few minutes, including skeletal mesh, textures, materials, and animations."}),"\n",(0,i.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(t.p,{children:"OS: Windows\r\nUnreal Engine version: 5.3 or 5.4\r\nYou will need an iPhone with Leap application installed to capture the facial animation data."}),"\n",(0,i.jsx)(t.h3,{id:"minimal-technical-requirements",children:"Minimal technical requirements"}),"\n",(0,i.jsx)(t.p,{children:"RAM: 16 Gb\r\nGPU: GeForce RTX 3050\r\nCPU: Intel i7 7th gen"}),"\n",(0,i.jsx)(t.h3,{id:"sample-project",children:"Sample project"}),"\n",(0,i.jsx)(t.p,{children:"The Leap plugin comes with a sample UE project to help you start with facial animation creation. Open the project by double-clicking on the LeapDemo. project file."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(9662).A+"",width:"886",height:"302"})}),"\n",(0,i.jsx)(t.p,{children:"Another option - in the Unreal Engine Project browser, click on the Browse button in the Recent Project partition and provide a path to the LeapDemo:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(6994).A+"",width:"1478",height:"1011"})}),"\n",(0,i.jsxs)(t.p,{children:["When you open the project, the Leap sample level will be loaded. You can explore the sample animation provided with the project at ",(0,i.jsx)(t.code,{children:"/Content/AvatarSdkLeap/Victor"})]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(5146).A+"",width:"1470",height:"779"})}),"\n",(0,i.jsxs)(t.p,{children:["To import your animation, click the ",(0,i.jsx)(t.code,{children:"Window->Avatar SDK Leap"})," menu to open the plugin window."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(46).A+"",width:"625",height:"896"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(6622).A+"",width:"848",height:"604"})}),"\n",(0,i.jsxs)(t.p,{children:["Choose the name for your ",(0,i.jsx)(t.a,{href:"https://dev.epicgames.com/documentation/en-us/unreal-engine/sequences-shots-and-takes-in-unreal-engine#levelsequences",children:"level sequence"}),", and choose a type of avatar to be generated. Click the ",(0,i.jsx)(t.code,{children:"Use materials for Ray tracing"})," if you intend to use path tracing to render your level sequence. For your first try, we recommend leaving it in its default state."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(629).A+"",width:"848",height:"604"})}),"\n",(0,i.jsxs)(t.p,{children:["Click on the ",(0,i.jsx)(t.code,{children:"Import Leap Animation"})," button and provide a path with the archive you got after capturing data with your iPhone Leap application. After that, the processing begins."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(7156).A+"",width:"1600",height:"820"})}),"\n",(0,i.jsx)(t.p,{children:"Depending on your hardware setup, processing may take from 4 to 5 minutes.\r\nWhen the processing is finished, you will be able to open the resulting level sequence or explore the assets created by Leap in the destination folder."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(7740).A+"",width:"836",height:"596"})}),"\n",(0,i.jsxs)(t.p,{children:["The imported animation files may be found in the ",(0,i.jsx)(t.code,{children:"/Content/AvatarSdkLeap"})," directory:"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(1551).A+"",width:"679",height:"328"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(8936).A+"",width:"1481",height:"463"})}),"\n",(0,i.jsx)(t.p,{children:"Created level sequence contains tracks for the camera, texture and body skeletal mesh. You can edit the created tracks and assets according to your requirements."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(3101).A+"",width:"1600",height:"451"})}),"\n",(0,i.jsxs)(t.p,{children:["A corresponding Level Sequence Actor will be placed on the current opened level. This Level Sequence Actor may be used to create cinematic content for games and traditional animation in Unreal Engine. The Actor is placed at the location that can be configured in the plugin settings ",(0,i.jsx)(t.code,{children:"Edit->Project Settings->Avatar SDK Leap"}),":"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(8180).A+"",width:"1600",height:"432"})}),"\n",(0,i.jsx)(t.h3,{id:"rendering-video",children:"Rendering Video"}),"\n",(0,i.jsx)(t.p,{children:"To render the image frame sequence from your Level Sequence, click on the corresponding button in the Sequencer:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(1894).A+"",width:"1076",height:"572"})}),"\n",(0,i.jsxs)(t.p,{children:["Choose among the predefined Rendering Settings, or create your own. We recommend to use the ",(0,i.jsx)(t.code,{children:"RA_No_PT_Config_FAST"})," to get the fastest result:"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(675).A+"",width:"1020",height:"533"})}),"\n",(0,i.jsxs)(t.p,{children:["The config ",(0,i.jsx)(t.code,{children:"RA_No_PT_Config_MID"})," should give better results and does not use path tracing.\r\nThe config ",(0,i.jsx)(t.code,{children:"RA_PT_Config"})," is made for path tracing rendering. These configurations represent a trade-off between quality and rendering time.\r\nClick on the ",(0,i.jsx)(t.code,{children:"Render Local"})," button to start the rendering:"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(9478).A+"",width:"1153",height:"415"})}),"\n",(0,i.jsxs)(t.p,{children:["By default, the Level Sequence will be rendered as a sequence of PNG images that can be found in the ",(0,i.jsx)(t.code,{children:"\\Saved\\MovieRenders"})," subdirectory of the project directory. Use video editing software to create video from the set of images. A good option is to use FFmpeg. In such case, the command may look like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'ffmpeg -r 60  -i "Saved\\MovieRenders\\LevelSequence_RealisticAnim_0.%04d.png" -c:v libx265 -crf 2 -vf format=yuv420p10le -tag:v hvc1  "I:\\renders\\video0.mp4" -y\n'})}),"\n",(0,i.jsx)(t.h3,{id:"support",children:"Support"}),"\n",(0,i.jsxs)(t.p,{children:["Please feel free to ask any questions about the Avatar SDK Leap at ",(0,i.jsx)(t.a,{href:"mailto:support@avatarsdk.com",children:"support@avatarsdk.com"})]})]})}function p(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8936:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_assets-731573f31c735defa76b98f0b7cf3052.png"},1551:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_dest-c02b204965c2cc200f58a647f9d3d67f.png"},9662:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_dir-d95fcf0d6a9be62f8ceaca5e78180e32.png"},537:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_export-363837287c5f12fe2e33a85b7ca48e0e.png"},7156:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_import-3fab2592510f041432e558ecf2a3310e.png"},6994:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_launch-83b1cc673916b73ce693f0b9ea412d25.png"},46:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_menu-53746b213c26db54bc7a75e9867b4efd.png"},9468:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_record-65d49a9bfca02d9fa24072489d6add1b.png"},9478:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_render_start-9bb997aafd4b05a562238187ee8c9db6.png"},675:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_rendering-005019fc3d65c9c1b87cb6ae204cd565.png"},3101:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_seq1-49f86a96a90de4d7b495ba5ff693adbc.png"},1894:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_seq2-775cac7bf041eb2359dab400e833537c.png"},8180:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_settings-d6e600d916623823dcb9cc81556485e2.png"},1543:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_start-fe8a94797bc1e1cf430f33c32329be2b.png"},5146:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_victor-644fb362d033cf98b5ff81b506a29f9c.png"},6622:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_window1-972e83c0c7260f90e175806791bdf226.png"},629:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_window2-f4fadfe8e6e75fbdd49a534e74f6c1f3.png"},7740:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/leap_window3-b2554426323261a45476d1c5a56b0b09.png"},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(6540);const a={},s=i.createContext(a);function r(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);